{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Prototyping Notebook\n",
    "\n",
    "Quick experiments with LLM providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment and imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from modules.llm_provider import agent\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, List, Optional, Union\n",
    "from enum import Enum\n",
    "import json\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚠️ Clear All Outputs before committing to prevent leaking sensitive data! ⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changelog\n",
    "\n",
    "All notable changes to **Screening Cheatsheet Response Schema** will be documented in this cell.\n",
    "\n",
    "The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.1.0/),\n",
    "and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n",
    "\n",
    "## [Unreleased]\n",
    "### Changed\n",
    "- Latest changelog revisions\n",
    "- Updated `.env.example` to follow latest changes\n",
    "## [0.0.1-alpha.2+8404e0a] - 2025-06-17\n",
    "### Added\n",
    "- `FinalDecision`\n",
    "- Default flow diagram pseudocode in `ScreeningCheatsheet`\n",
    "- `is_last_step` in `FlowDiagramStep` for pseudocode to make sense\n",
    "- Some [provisions](https://github.com/pvzhelnov/cheatsheet_parser/commit/7c6fae296de066c761db7a4dd7a224eebf64ae7f) against leaking sensitive data\n",
    "- This changelog\n",
    "### Changed\n",
    "- Definitions in `FlowDiagramStep` to handle final decision\n",
    "- Handling of flow diagram in `ScreeningCheatsheet` to accommodate additions\n",
    "- Migrated the repo to a [more recent version](https://github.com/pvzhelnov/gerpa/tree/1ff0f1bcd1c63e4dd27a3f0b4e052f0bbad70bb6) of GERPA\n",
    "- Quite importantly, the migration to new GERPA led to some changes to default LLM inference settings, in particular, all agents are now run with the following config (unless requested otherwise):\n",
    "  - `temperature` = 0.0\n",
    "  - `top_k` = 40\n",
    "  - `top_p` = 0.95\n",
    "  - `seed` = 42 (if offered by provider)\n",
    "  - `safety_settings` set to provider-specific values to turn all safety provisions off\n",
    "### Tested\n",
    "- On the same sample cheat sheet\n",
    "## 0.0.1-alpha.1+outside.of.this.repo - 2025-06-03\n",
    "### Added\n",
    "- `ScreeningCheatsheet` and all the scaffolding\n",
    "- System instruction (SHA-256 hash: `64362907`)\n",
    "- Model used: `gemini-2.5-flash-preview-05-20`\n",
    "### Tested\n",
    "- On a sample cheat sheet\n",
    "\n",
    "[unreleased]: https://github.com/pvzhelnov/cheatsheet_parser/compare/8404e0a0c6332addeb2992cfda5d1ed3f68a2469...HEAD\n",
    "[0.0.1-alpha.2+8404e0a]: https://github.com/pvzhelnov/cheatsheet_parser/tree/8404e0a0c6332addeb2992cfda5d1ed3f68a2469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheatsheetQuestionUID(BaseModel):\n",
    "    unique_question_id: int\n",
    "\n",
    "class ResponseOption(BaseModel):\n",
    "    value: Literal['Yes', 'No', 'Maybe/Unclear']\n",
    "    notes: List[str] = Field(..., description=\"if the study...\")\n",
    "\n",
    "class CheatsheetQuestion(BaseModel):\n",
    "    question_uid: CheatsheetQuestionUID\n",
    "    question_formulation: str\n",
    "    responses: List[ResponseOption]\n",
    "    question_note: Optional[str] = Field(..., description=\"Any question-wide note(s), if present.\")\n",
    "\n",
    "class FinalDecision(BaseModel):\n",
    "    decision: Literal['Exclude', 'Include']\n",
    "\n",
    "class FlowDiagramStep(BaseModel):\n",
    "    step_id: int\n",
    "    is_last_step: bool\n",
    "    on_yes: Union[CheatsheetQuestionUID, FinalDecision]\n",
    "    on_maybe: Union[CheatsheetQuestionUID, FinalDecision]\n",
    "    on_no: Union[CheatsheetQuestionUID, FinalDecision]\n",
    "\n",
    "class ScreeningCheatsheet(BaseModel):\n",
    "    questions: List[CheatsheetQuestion]\n",
    "    flow_diagram: List[FlowDiagramStep] = Field(..., description=\"If you find a flow diagram in the input file, extract it. Otherwise implement the following pseudocode: { While is_last_step is False: { If Maybe/Yes Then Proceed to next step_id, Else Exclude } ; Once is_last_step is True: { If Maybe/Yes Then Include, Else Exclude } }\")\n",
    "\n",
    "print(json.dumps(ScreeningCheatsheet.model_json_schema(), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"You extract accurately data from a systematic review screening cheatsheet.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent\n",
    "LLMPROVIDER = \"gemini\"  # or \"openrouter\", \"ollama\"\n",
    "llm_agent = agent(\n",
    "    LLMPROVIDER,\n",
    "    ScreeningCheatsheet,\n",
    "    system_instruction=system_instruction,\n",
    "    model_name=\"gemini-2.5-flash-preview-05-20\")\n",
    "\n",
    "# Test prompt\n",
    "prompt = [\n",
    "    \"Here is the cheatsheet template:\",\n",
    "    f\"{os.getenv(\"CHEATSHEET_PDF_PATH\")}\",  # note: docx is apparently unsupported\n",
    "]\n",
    "\n",
    "start_time = time()\n",
    "response = llm_agent(prompt)\n",
    "end_time = time()\n",
    "print(f\"Execution time: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skip\n",
    "# Experiment with different providers\n",
    "providers = [\"gemini\", \"openrouter\", \"ollama\"]\n",
    "\n",
    "for provider in providers:\n",
    "    try:\n",
    "        print(f\"\\n--- Testing {provider} ---\")\n",
    "        test_agent = agent(provider)\n",
    "        response = test_agent(\"What is the capital of France?\")\n",
    "        print(f\"Response: {response.content[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {provider}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheatsheet_parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
