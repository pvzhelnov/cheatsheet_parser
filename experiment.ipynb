{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Prototyping Notebook\n",
    "\n",
    "Quick experiments with LLM providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment and imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from modules.llm_provider import agent\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, List, Optional, Union\n",
    "from enum import Enum\n",
    "import json\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚠️ Clear All Outputs before committing to prevent leaking sensitive data! ⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changelog\n",
    "\n",
    "All notable changes to **Screening Cheatsheet Response Schema** will be documented in this cell.\n",
    "\n",
    "The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.1.0/),\n",
    "and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n",
    "\n",
    "## [Unreleased]\n",
    "### Added\n",
    "- Example cheat sheets templates, inputs, and outputs\n",
    "### Changed\n",
    "- Latest changelog revisions\n",
    "- Updated `.env.example` to follow latest changes\n",
    "- Response options are dynamically detected from input\n",
    "## [0.0.1-alpha.2+8404e0a] - 2025-06-17\n",
    "### Added\n",
    "- `FinalDecision`\n",
    "- Default flow diagram pseudocode in `ScreeningCheatsheet`\n",
    "- `is_last_step` in `FlowDiagramStep` for pseudocode to make sense\n",
    "- Some [provisions](https://github.com/pvzhelnov/cheatsheet_parser/commit/7c6fae296de066c761db7a4dd7a224eebf64ae7f) against leaking sensitive data\n",
    "- This changelog\n",
    "### Changed\n",
    "- Definitions in `FlowDiagramStep` to handle final decision\n",
    "- Handling of flow diagram in `ScreeningCheatsheet` to accommodate additions\n",
    "- Migrated the repo to a [more recent version](https://github.com/pvzhelnov/gerpa/tree/1ff0f1bcd1c63e4dd27a3f0b4e052f0bbad70bb6) of GERPA\n",
    "- Quite importantly, the migration to new GERPA led to some changes to default LLM inference settings, in particular, all agents are now run with the following config (unless requested otherwise):\n",
    "  - `temperature` = 0.0\n",
    "  - `top_k` = 40\n",
    "  - `top_p` = 0.95\n",
    "  - `seed` = 42 (if offered by provider)\n",
    "  - `safety_settings` set to provider-specific values to turn all safety provisions off\n",
    "### Tested\n",
    "- On the same sample cheat sheet\n",
    "## 0.0.1-alpha.1+outside.of.this.repo - 2025-06-03\n",
    "### Added\n",
    "- `ScreeningCheatsheet` and all the scaffolding\n",
    "- System instruction (SHA-256 hash: `64362907`)\n",
    "- Model used: `gemini-2.5-flash-preview-05-20`\n",
    "### Tested\n",
    "- On a sample cheat sheet\n",
    "\n",
    "[unreleased]: https://github.com/pvzhelnov/cheatsheet_parser/compare/8404e0a0c6332addeb2992cfda5d1ed3f68a2469...HEAD\n",
    "[0.0.1-alpha.2+8404e0a]: https://github.com/pvzhelnov/cheatsheet_parser/tree/8404e0a0c6332addeb2992cfda5d1ed3f68a2469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"$defs\": {\n",
      "    \"CheatsheetQuestion\": {\n",
      "      \"properties\": {\n",
      "        \"question_uid\": {\n",
      "          \"$ref\": \"#/$defs/CheatsheetQuestionUID\"\n",
      "        },\n",
      "        \"question_formulation\": {\n",
      "          \"title\": \"Question Formulation\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"responses\": {\n",
      "          \"items\": {\n",
      "            \"$ref\": \"#/$defs/ResponseOption\"\n",
      "          },\n",
      "          \"title\": \"Responses\",\n",
      "          \"type\": \"array\"\n",
      "        },\n",
      "        \"question_note\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"type\": \"string\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"description\": \"Any question-wide note(s), if present.\",\n",
      "          \"title\": \"Question Note\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"question_uid\",\n",
      "        \"question_formulation\",\n",
      "        \"responses\",\n",
      "        \"question_note\"\n",
      "      ],\n",
      "      \"title\": \"CheatsheetQuestion\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"CheatsheetQuestionUID\": {\n",
      "      \"properties\": {\n",
      "        \"unique_question_id\": {\n",
      "          \"title\": \"Unique Question Id\",\n",
      "          \"type\": \"integer\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"unique_question_id\"\n",
      "      ],\n",
      "      \"title\": \"CheatsheetQuestionUID\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"FinalDecision\": {\n",
      "      \"properties\": {\n",
      "        \"decision\": {\n",
      "          \"enum\": [\n",
      "            \"Exclude\",\n",
      "            \"Include\"\n",
      "          ],\n",
      "          \"title\": \"Decision\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"decision\"\n",
      "      ],\n",
      "      \"title\": \"FinalDecision\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"FlowDiagramStep\": {\n",
      "      \"properties\": {\n",
      "        \"step_id\": {\n",
      "          \"title\": \"Step Id\",\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        \"is_last_step\": {\n",
      "          \"title\": \"Is Last Step\",\n",
      "          \"type\": \"boolean\"\n",
      "        },\n",
      "        \"on_response_option\": {\n",
      "          \"items\": {\n",
      "            \"$ref\": \"#/$defs/OnResponseOption\"\n",
      "          },\n",
      "          \"title\": \"On Response Option\",\n",
      "          \"type\": \"array\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"step_id\",\n",
      "        \"is_last_step\",\n",
      "        \"on_response_option\"\n",
      "      ],\n",
      "      \"title\": \"FlowDiagramStep\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"OnResponseOption\": {\n",
      "      \"properties\": {\n",
      "        \"response_option_unique_literal\": {\n",
      "          \"$ref\": \"#/$defs/ResponseOptionUniqueLiteral\"\n",
      "        },\n",
      "        \"action_to_take\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"$ref\": \"#/$defs/CheatsheetQuestionUID\"\n",
      "            },\n",
      "            {\n",
      "              \"$ref\": \"#/$defs/FinalDecision\"\n",
      "            }\n",
      "          ],\n",
      "          \"title\": \"Action To Take\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"response_option_unique_literal\",\n",
      "        \"action_to_take\"\n",
      "      ],\n",
      "      \"title\": \"OnResponseOption\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"ResponseOption\": {\n",
      "      \"properties\": {\n",
      "        \"value\": {\n",
      "          \"$ref\": \"#/$defs/ResponseOptionUniqueLiteral\"\n",
      "        },\n",
      "        \"notes\": {\n",
      "          \"description\": \"if the study...\",\n",
      "          \"items\": {\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"title\": \"Notes\",\n",
      "          \"type\": \"array\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"value\",\n",
      "        \"notes\"\n",
      "      ],\n",
      "      \"title\": \"ResponseOption\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"ResponseOptionUniqueLiteral\": {\n",
      "      \"properties\": {\n",
      "        \"string_value\": {\n",
      "          \"description\": \"Capture the literal value verbatim as described in the input file(s).\",\n",
      "          \"title\": \"String Value\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"unique_literal\": {\n",
      "          \"description\": \"May occasionally include other literal value types depending on context. Select the closest one in case of obvious variants, or select Other if no matching literal value is found.\",\n",
      "          \"enum\": [\n",
      "            \"Yes\",\n",
      "            \"No\",\n",
      "            \"Maybe\",\n",
      "            \"Other\"\n",
      "          ],\n",
      "          \"title\": \"Unique Literal\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"string_value\",\n",
      "        \"unique_literal\"\n",
      "      ],\n",
      "      \"title\": \"ResponseOptionUniqueLiteral\",\n",
      "      \"type\": \"object\"\n",
      "    }\n",
      "  },\n",
      "  \"properties\": {\n",
      "    \"allowed_response_options\": {\n",
      "      \"description\": \"Deduce these from the entire preceding context. Consider obviously equivalent response options like case differences or typos to be equivalent and select the most consistent variant.\",\n",
      "      \"items\": {\n",
      "        \"$ref\": \"#/$defs/ResponseOptionUniqueLiteral\"\n",
      "      },\n",
      "      \"title\": \"Allowed Response Options\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"questions\": {\n",
      "      \"items\": {\n",
      "        \"$ref\": \"#/$defs/CheatsheetQuestion\"\n",
      "      },\n",
      "      \"title\": \"Questions\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"flow_diagram_detected\": {\n",
      "      \"description\": \"Is there a flow diagram in the input file(s)?\",\n",
      "      \"title\": \"Flow Diagram Detected\",\n",
      "      \"type\": \"boolean\"\n",
      "    },\n",
      "    \"flow_diagram\": {\n",
      "      \"description\": \"If flow_diagram_detected, extract it. Otherwise implement the following pseudocode: { While is_last_step is False: { If Maybe/Yes Then Proceed to next step_id, Else Exclude } ; Once is_last_step is True: { If Maybe/Yes Then Include, Else Exclude } }\",\n",
      "      \"items\": {\n",
      "        \"$ref\": \"#/$defs/FlowDiagramStep\"\n",
      "      },\n",
      "      \"title\": \"Flow Diagram\",\n",
      "      \"type\": \"array\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"allowed_response_options\",\n",
      "    \"questions\",\n",
      "    \"flow_diagram_detected\",\n",
      "    \"flow_diagram\"\n",
      "  ],\n",
      "  \"title\": \"ScreeningCheatsheet\",\n",
      "  \"type\": \"object\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class CheatsheetQuestionUID(BaseModel):\n",
    "    unique_question_id: int\n",
    "\n",
    "# TO DO: Separate into two LLM calls and implement using generics\n",
    "\n",
    "class ResponseOptionUniqueLiteral(BaseModel):\n",
    "    string_value: str = Field(..., description=\"Capture the literal value verbatim as described in the input file(s).\")\n",
    "    unique_literal: Literal['Yes', 'No', 'Maybe', 'Other'] = Field(..., description=\"May occasionally include other literal value types depending on context. Select the closest one in case of obvious variants, or select Other if no matching literal value is found.\")\n",
    "\n",
    "class ResponseOption(BaseModel):\n",
    "    value: ResponseOptionUniqueLiteral\n",
    "    notes: List[str] = Field(..., description=\"if the study...\")\n",
    "\n",
    "class CheatsheetQuestion(BaseModel):\n",
    "    question_uid: CheatsheetQuestionUID\n",
    "    question_formulation: str\n",
    "    responses: List[ResponseOption]\n",
    "    question_note: Optional[str] = Field(..., description=\"Any question-wide note(s), if present.\")\n",
    "\n",
    "class FinalDecision(BaseModel):\n",
    "    decision: Literal['Exclude', 'Include']\n",
    "\n",
    "class OnResponseOption(BaseModel):\n",
    "    response_option_unique_literal: ResponseOptionUniqueLiteral\n",
    "    action_to_take: Union[CheatsheetQuestionUID, FinalDecision]\n",
    "\n",
    "class FlowDiagramStep(BaseModel):\n",
    "    step_id: int\n",
    "    is_last_step: bool\n",
    "    on_response_option: List[OnResponseOption]\n",
    "\n",
    "class ScreeningCheatsheet(BaseModel):\n",
    "    allowed_response_options: List[ResponseOptionUniqueLiteral] = Field(..., description=\"Deduce these from the entire preceding context. Consider obviously equivalent response options like case differences or typos to be equivalent and select the most consistent variant.\")\n",
    "    questions: List[CheatsheetQuestion]\n",
    "    flow_diagram_detected: bool = Field(..., description=\"Is there a flow diagram in the input file(s)?\")\n",
    "    flow_diagram: List[FlowDiagramStep] = Field(..., description=\"If flow_diagram_detected, extract it. Otherwise implement the following pseudocode: { While is_last_step is False: { If Maybe/Yes Then Proceed to next step_id, Else Exclude } ; Once is_last_step is True: { If Maybe/Yes Then Include, Else Exclude } }\")\n",
    "\n",
    "print(json.dumps(ScreeningCheatsheet.model_json_schema(), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"You extract accurately data from a systematic review screening cheatsheet.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8-UBrWLqkL7HQjNJA8iPHWT8v9ptQ5JKRln1hwd_NlBSTwhbY09-V2fmlmwbKi2HkDB0fGn4gbLDGyrpz9puURDfNKCr9x0OnLVGj9ubHk&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent \"HTTP/1.1 200 OK\"\n",
      "INFO:google_genai.models:AFC remote call 1 is done.\n",
      "2025-07-15 13:56:50,140 - llm_agent_llm_provider - INFO - LLM Response: {\n",
      "  \"provider\": {\n",
      "    \"provider_name\": \"gemini\",\n",
      "    \"safety_settings\": \"[SafetySetting(method=None, category=<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 'HARM_CATEGORY_HATE_SPEECH'>, threshold=<HarmBlockThreshold.BLOCK_NONE: 'BLOCK_NONE'>), SafetySetting(method=None, category=<HarmCategory.HARM_CATEGORY_HARASSMENT: 'HARM_CATEGORY_HARASSMENT'>, threshold=<HarmBlockThreshold.BLOCK_NONE: 'BLOCK_NONE'>), SafetySetting(method=None, category=<HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 'HARM_CATEGORY_SEXUALLY_EXPLICIT'>, threshold=<HarmBlockThreshold.BLOCK_NONE: 'BLOCK_NONE'>), SafetySetting(method=None, category=<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 'HARM_CATEGORY_DANGEROUS_CONTENT'>, threshold=<HarmBlockThreshold.BLOCK_NONE: 'BLOCK_NONE'>), SafetySetting(method=None, category=<HarmCategory.HARM_CATEGORY_CIVIC_INTEGRITY: 'HARM_CATEGORY_CIVIC_INTEGRITY'>, threshold=<HarmBlockThreshold.BLOCK_NONE: 'BLOCK_NONE'>)]\"\n",
      "  },\n",
      "  \"model\": {\n",
      "    \"model_name\": \"gemini-2.5-flash-preview-05-20\",\n",
      "    \"config\": {\n",
      "      \"temperature\": 0.0,\n",
      "      \"top_k\": 40,\n",
      "      \"top_p\": 0.95,\n",
      "      \"seed\": 42\n",
      "    }\n",
      "  },\n",
      "  \"request\": {\n",
      "    \"prompt_hash\": \"4f1d6478\",\n",
      "    \"system_instruction_hash\": \"64362907\",\n",
      "    \"response_schema\": \"ScreeningCheatsheet\"\n",
      "  },\n",
      "  \"response\": {\n",
      "    \"content\": \"{\\\"allowed_response_options\\\":[{\\\"string_value\\\":\\\"YES\\\",\\\"unique_literal\\\":\\\"Yes\\\"},{\\\"string_value\\\":\\\"NO\\\",\\\"unique_literal\\\":\\\"No\\\"},{\\\"string_value\\\":\\\"MAYBE\\\",\\\"unique_literal\\\":\\\"Maybe\\\"}],\\\"questions\\\":[{\\\"question_uid\\\":{...\",\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 1558,\n",
      "      \"completion_tokens\": 2151,\n",
      "      \"total_tokens\": 5529\n",
      "    },\n",
      "    \"metadata\": {\n",
      "      \"request_timestamp\": \"2025-07-15T13:56:34.880816\",\n",
      "      \"response_timestamp\": \"2025-07-15T13:56:50.140428\",\n",
      "      \"finish_reason\": \"completed\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "INFO:llm_agent_llm_provider:LLM Response: {\n",
      "  \"provider\": {\n",
      "    \"provider_name\": \"gemini\",\n",
      "    \"safety_settings\": \"[SafetySetting(method=None, category=<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 'HARM_CATEGORY_HATE_SPEECH'>, threshold=<HarmBlockThreshold.BLOCK_NONE: 'BLOCK_NONE'>), SafetySetting(method=None, category=<HarmCategory.HARM_CATEGORY_HARASSMENT: 'HARM_CATEGORY_HARASSMENT'>, threshold=<HarmBlockThreshold.BLOCK_NONE: 'BLOCK_NONE'>), SafetySetting(method=None, category=<HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 'HARM_CATEGORY_SEXUALLY_EXPLICIT'>, threshold=<HarmBlockThreshold.BLOCK_NONE: 'BLOCK_NONE'>), SafetySetting(method=None, category=<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 'HARM_CATEGORY_DANGEROUS_CONTENT'>, threshold=<HarmBlockThreshold.BLOCK_NONE: 'BLOCK_NONE'>), SafetySetting(method=None, category=<HarmCategory.HARM_CATEGORY_CIVIC_INTEGRITY: 'HARM_CATEGORY_CIVIC_INTEGRITY'>, threshold=<HarmBlockThreshold.BLOCK_NONE: 'BLOCK_NONE'>)]\"\n",
      "  },\n",
      "  \"model\": {\n",
      "    \"model_name\": \"gemini-2.5-flash-preview-05-20\",\n",
      "    \"config\": {\n",
      "      \"temperature\": 0.0,\n",
      "      \"top_k\": 40,\n",
      "      \"top_p\": 0.95,\n",
      "      \"seed\": 42\n",
      "    }\n",
      "  },\n",
      "  \"request\": {\n",
      "    \"prompt_hash\": \"4f1d6478\",\n",
      "    \"system_instruction_hash\": \"64362907\",\n",
      "    \"response_schema\": \"ScreeningCheatsheet\"\n",
      "  },\n",
      "  \"response\": {\n",
      "    \"content\": \"{\\\"allowed_response_options\\\":[{\\\"string_value\\\":\\\"YES\\\",\\\"unique_literal\\\":\\\"Yes\\\"},{\\\"string_value\\\":\\\"NO\\\",\\\"unique_literal\\\":\\\"No\\\"},{\\\"string_value\\\":\\\"MAYBE\\\",\\\"unique_literal\\\":\\\"Maybe\\\"}],\\\"questions\\\":[{\\\"question_uid\\\":{...\",\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 1558,\n",
      "      \"completion_tokens\": 2151,\n",
      "      \"total_tokens\": 5529\n",
      "    },\n",
      "    \"metadata\": {\n",
      "      \"request_timestamp\": \"2025-07-15T13:56:34.880816\",\n",
      "      \"response_timestamp\": \"2025-07-15T13:56:50.140428\",\n",
      "      \"finish_reason\": \"completed\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 16.4418 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create agent\n",
    "LLMPROVIDER = \"gemini\"  # or \"openrouter\", \"ollama\"\n",
    "llm_agent = agent(\n",
    "    LLMPROVIDER,\n",
    "    ScreeningCheatsheet,\n",
    "    system_instruction=system_instruction,\n",
    "    model_name=\"gemini-2.5-flash-preview-05-20\")\n",
    "\n",
    "# Test prompt\n",
    "prompt = [\n",
    "    \"Here is the cheatsheet template:\",\n",
    "    f\"{os.getenv(\"CHEATSHEET_PDF_PATH\")}\"  # note: docx is apparently unsupported\n",
    "    #\"Here is the cheatsheet flow diagram:\",\n",
    "    #f\"{os.getenv(\"CHEATSHEET_FLOW_DIAGRAM_PDF_PATH\")}\"\n",
    "]\n",
    "\n",
    "start_time = time()\n",
    "response = llm_agent(prompt)\n",
    "end_time = time()\n",
    "print(f\"Execution time: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(99714) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "%%script echo skip\n",
    "# Experiment with different providers\n",
    "providers = [\"gemini\", \"openrouter\", \"ollama\"]\n",
    "\n",
    "for provider in providers:\n",
    "    try:\n",
    "        print(f\"\\n--- Testing {provider} ---\")\n",
    "        test_agent = agent(provider)\n",
    "        response = test_agent(\"What is the capital of France?\")\n",
    "        print(f\"Response: {response.content[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {provider}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheatsheet_parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
